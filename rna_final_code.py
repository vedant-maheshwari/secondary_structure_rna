# -*- coding: utf-8 -*-
"""RNA-final code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C8wyz66PwdoNvP0IAZLcBCZDSB9TfVgW

#Making of Dataset
"""

# import pandas as pd

# # Load your dataset
# df = pd.read_csv("/content/dataset.csv")

# # Group by the 'Header' and concatenate nucleotides into a sequence
# df['Nucleotide Sequence'] = df.groupby('Header')['Nucleotide'].transform(lambda x: ''.join(x))

# # Drop duplicates to keep only one row per sequence
# df = df.drop_duplicates(subset=['Header', 'Nucleotide Sequence'])

# # Save the modified dataset
# df.to_csv("/content/newdataset.csv", index=False)

# Install dependencies
!apt-get update
!apt-get install -y build-essential libgsl-dev libmpfr-dev

# Download ViennaRNA source code
!wget https://www.tbi.univie.ac.at/RNA/download/sourcecode/2_4_x/ViennaRNA-2.4.17.tar.gz

# Extract the files
!tar -xvzf ViennaRNA-2.4.17.tar.gz

# Commented out IPython magic to ensure Python compatibility.
# Change directory to the ViennaRNA folder
# %cd ViennaRNA-2.4.17

# Configure and compile
!./configure
!make
!make install

!RNAfold --version

import pandas as pd
import subprocess

# Sample dataset with nucleotide sequences
df = pd.read_csv('/content/newdataset.csv')  # Replace with your actual dataset file

# Initialize a new list to store structures
structures = []

for seq in df['Nucleotide Sequence']:  # Replace with actual column name
    # Run RNAfold to predict the secondary structure
    process = subprocess.run(['RNAfold'], input=seq, capture_output=True, text=True)
    result = process.stdout.strip().split('\n')
    structure = result[1].split()[0]  # Extract structure from output
    structures.append(structure)

# Add the predicted structures as a new column in the dataframe
df['Structure'] = structures

# Save to a new CSV file
df.to_csv('/content/newdataset1.csv', index=False)

df.head()

"""#LSTM"""

import pandas as pd
import numpy as np

# Load the DataFrame
df = pd.read_csv('/content/newdataset1.csv')
df.head()

import pandas as pd
import numpy as np

# Read the CSV file
df = pd.read_csv('/content/newdataset1.csv')

# Define the nucleotides
nucleotides = ['A', 'U', 'G', 'C']
max_length = max(df['Nucleotide Sequence'].str.len())  # Get the maximum length of nucleotide sequences

# Create a mapping for nucleotides
one_hot_map = {nucleotide: i for i, nucleotide in enumerate(nucleotides)}

# Function to one-hot encode a sequence of nucleotides
def one_hot_encode_sequence(sequence):
    one_hot = np.zeros((max_length, len(nucleotides)), dtype=int)  # Initialize with zeros
    for i, nucleotide in enumerate(sequence):
        if nucleotide in one_hot_map:
            one_hot[i, one_hot_map[nucleotide]] = 1
    return one_hot

# Apply the one-hot encoding to each nucleotide sequence
one_hot_encoded_data = df['Nucleotide Sequence'].apply(one_hot_encode_sequence)

# Stack the one-hot encoded arrays into a single array
one_hot_encoded_flat = np.stack(one_hot_encoded_data.values)

# Reshape to (number_of_sequences, max_length * number_of_nucleotides)
one_hot_encoded_flat = one_hot_encoded_flat.reshape(one_hot_encoded_flat.shape[0], -1)

# Create a DataFrame from the flattened one-hot encoded data
one_hot_df = pd.DataFrame(one_hot_encoded_flat)

# Concatenate the original DataFrame with the one-hot encoded nucleotides
encoded_df = pd.concat([df[['Header', 'Nucleotide Sequence', 'Structure']], one_hot_df], axis=1)

# Save the one-hot encoded data to a new CSV file
encoded_df.to_csv('dataset.csv', index=False)
print("One-hot encoded data has been saved to 'dataset.csv'")

"""##Train the Model"""

import pandas as pd
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load the dataset
df = pd.read_csv('/content/dataset.csv')
#df.head()

# Extract the one-hot encoded nucleotide features (X)
X = df.iloc[:, 3:].values  # Exclude 'Header', 'Nucleotide Sequence', and 'Structure' columns

# Map the structure symbols to numerical values
structure_map = {'.': 0, '(': 1, ')': 2}
Y_sequences = df['Structure'].apply(lambda x: [structure_map[char] for char in x]).tolist()

# Ensure X and Y have compatible shapes
num_samples = min(len(X), len(Y_sequences))  # Adjust to the smallest sample count if needed
X = X[:num_samples]

# Reshape X for LSTM input (samples, timesteps, features)
X = X.reshape(X.shape[0], -1, 4)

# Pad Y sequences to match the number of timesteps in X
Y_padded = pad_sequences(Y_sequences, maxlen=X.shape[1], padding='post', value=0)

# Convert Y_padded to a numpy array
Y = np.array(Y_padded)

# Build the LSTM Model
model = Sequential()
model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
model.add(Dense(3, activation='softmax'))  # 3 classes for ., (, and )

# Compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
model.fit(X, Y, epochs=50, batch_size=32)

import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np

# Load the dataset
df = pd.read_csv('/content/dataset.csv')

# Extract the one-hot encoded nucleotide features (X)
X = df.iloc[:, 3:].values  # Exclude 'Header', 'Nucleotide Sequence', and 'Structure' columns

# Map the structure symbols to numerical values
structure_map = {'.': 0, '(': 1, ')': 2}
Y_sequences = df['Structure'].apply(lambda x: [structure_map[char] for char in x]).tolist()

# Ensure X and Y have compatible shapes
num_samples = min(len(X), len(Y_sequences))  # Adjust to the smallest sample count if needed
X = X[:num_samples]

# Reshape X for LSTM input (samples, timesteps, features)
X = X.reshape(X.shape[0], -1, 4)

# Pad Y sequences to match the number of timesteps in X
Y_padded = pad_sequences(Y_sequences, maxlen=X.shape[1], padding='post', value=0)

# Convert Y_padded to a numpy array
Y = np.array(Y_padded)

# Split the dataset into training and validation sets
X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)

# Build the LSTM Model
model = Sequential()
model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
model.add(Dense(3, activation='softmax'))  # 3 classes for ., (, and )

# Compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model and capture the history
history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=100, batch_size=32)

# Plotting epoch vs loss
plt.figure(figsize=(10, 5))
plt.plot(history.history['loss'], label='Training Loss', color='blue')
plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')
plt.title('Epoch vs Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.show()

import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np

# Load the dataset
df = pd.read_csv('/content/dataset.csv')

# Extract the one-hot encoded nucleotide features (X)
X = df.iloc[:, 3:].values  # Exclude 'Header', 'Nucleotide Sequence', and 'Structure' columns

# Map the structure symbols to numerical values
structure_map = {'.': 0, '(': 1, ')': 2}
Y_sequences = df['Structure'].apply(lambda x: [structure_map[char] for char in x]).tolist()

# Ensure X and Y have compatible shapes
num_samples = min(len(X), len(Y_sequences))  # Adjust to the smallest sample count if needed
X = X[:num_samples]

# Reshape X for LSTM input (samples, timesteps, features)
X = X.reshape(X.shape[0], -1, 4)

# Pad Y sequences to match the number of timesteps in X
Y_padded = pad_sequences(Y_sequences, maxlen=X.shape[1], padding='post', value=0)

# Convert Y_padded to a numpy array
Y = np.array(Y_padded)

# Split the dataset into training and validation sets
X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)

# Build the LSTM Model
model = Sequential()
model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))
model.add(Dense(3, activation='softmax'))  # 3 classes for ., (, and )

# Compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model and capture the history
history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=50, batch_size=32)

# Plotting loss and accuracy
plt.figure(figsize=(14, 6))

# Plot Loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss', color='blue')
plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')
plt.title('Epoch vs Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid()

# Plot Accuracy
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')
plt.title('Epoch vs Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid()

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
import pandas as pd
import numpy as np
import tensorflow as tf

# Load the dataset
df = pd.read_csv('/content/dataset.csv')

def focal_loss(gamma=2., alpha=0.25):
    def focal_loss_fixed(y_true, y_pred):
        y_true = tf.cast(y_true, tf.int32)
        y_true_one_hot = tf.one_hot(y_true, depth=y_pred.shape[-1])
        cross_entropy = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)
        weight = tf.pow(1 - tf.reduce_max(y_pred * y_true_one_hot, axis=-1), gamma)
        focal_loss = alpha * weight * cross_entropy
        return focal_loss
    return focal_loss_fixed

# Preprocess X and Y as before, then ensure correct shape for Y
Y_padded = pad_sequences(Y_sequences, maxlen=X.shape[1], padding='post', value=0)
Y = np.array(Y_padded)

# Ensure shape is correct for sparse categorical cross-entropy
Y = Y.reshape(Y.shape[0], Y.shape[1])

# Split dataset into training, validation, and test sets (e.g., 70% train, 15% validation, 15% test)
X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, random_state=42)
X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)

# Define model
model = Sequential([
    LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences=True),
    Dense(3, activation='softmax')
])

# Compile the model with focal loss
model.compile(loss=focal_loss(gamma=2., alpha=0.25), optimizer='adam', metrics=['accuracy'])

# Train the model
history = model.fit(
    X_train, Y_train,
    validation_data=(X_val, Y_val),
    epochs=50,
    batch_size=32
)

# Plotting loss and accuracy
plt.figure(figsize=(14, 6))

# Plot Loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss', color='blue')
plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')
plt.title('Epoch vs Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid()

# Plot Accuracy
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')
plt.title('Epoch vs Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid()

plt.tight_layout()
plt.show()

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(X_test, Y_test)
print(f"Test Loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")

test_loss, test_accuracy = model.evaluate(X_val, Y_val)
print(f"Validation Loss: {test_loss:.4f}")
print(f"Validation Accuracy: {test_accuracy:.4f}")

predictions = model.predict(X_val)
predictions_classes = np.argmax(predictions, axis=-1)

for i in range(5):  # Show 5 samples
    print(f"True Structure:    {Y_val[i]}")
    print(f"Predicted Structure: {predictions_classes[i]}")
    print("\n")

structure_map_inv = {0: '.', 1: '(', 2: ')'}
predicted_structure = ["".join([structure_map_inv[char] for char in seq]) for seq in predictions_classes]

model.save('/content/rna_structure_model.h5')

from sklearn.metrics import accuracy_score, f1_score, classification_report
import numpy as np

# Get predictions from the model and convert them to class labels (0, 1, 2)
y_pred = model.predict(X_test)
y_pred_labels = np.argmax(y_pred, axis=-1)  # Convert probabilities to class labels

# Flatten y_test and y_pred_labels for compatibility with metrics
y_test_flat = Y_test.flatten()
y_pred_flat = y_pred_labels.flatten()

# Calculate accuracy
accuracy = accuracy_score(y_test_flat, y_pred_flat)

# Calculate F1 scores for each class (0 for '.', 1 for '(', 2 for ')')
f1_scores = f1_score(y_test_flat, y_pred_flat, average=None, labels=[0, 1, 2])

# Print results
print("Evaluation Results:")
print(f"Accuracy: {accuracy * 100:.2f}%")
print(f"F1 Score for '.': {f1_scores[0]:.2f}")
print(f"F1 Score for '(': {f1_scores[1]:.2f}")
print(f"F1 Score for ')': {f1_scores[2]:.2f}")
print("\nDetailed Classification Report:")
print(classification_report(y_test_flat, y_pred_flat, labels=[0, 1, 2], target_names=['.', '(', ')']))

"""##Energy"""

!pip install seqfold

import pandas as pd
from seqfold import fold, dg, dot_bracket
import re

# Load your RNA dataset
df = pd.read_csv('/content/rna_sequences.csv')

# Define a function to clean sequence and calculate MFE and dot-bracket notation
def calculate_mfe_and_dot_bracket(sequence):
    # Keep only valid RNA bases
    cleaned_seq = re.sub(r'[^AUGC]', '', sequence.upper())

    # Calculate MFE
    mfe = dg(cleaned_seq, temp=37.0)

    # Get the folded structures for additional details
    structs = fold(cleaned_seq)

    # Get dot-bracket notation
    dot_bracket_notation = dot_bracket(cleaned_seq, structs)

    return mfe, dot_bracket_notation

# Apply the function to each sequence in the dataset, with error handling
df[['MFE', 'Dot Bracket Notation']] = df['Nucleotide Sequence'].apply(
    lambda seq: pd.Series(calculate_mfe_and_dot_bracket(seq))
)

# Save the results to a new CSV file
df.to_csv('/content/rna_sequences_with_mfe.csv', index=False)

print("Calculation complete. Results saved in 'rna_sequences_with_mfe.csv'")

import pandas as pd

# Load the RNA dataset
df = pd.read_csv('/content/rna_sequences.csv')

# Bond pair energies in kcal/mol for RNA base pairs
bond_energies = {
    'AU': -2.1,
    'UA': -2.1,
    'GC': -3.4,
    'CG': -3.4,
    'GU': -0.9,
    'UG': -0.9
}

def calculate_bond_energy(structure, sequence):
    """
    Calculates bond energy for an RNA structure based on base pair types.

    Parameters:
    structure (str): Dot-bracket notation of the RNA structure.
    sequence (str): Nucleotide sequence corresponding to the structure.

    Returns:
    float: Total bond energy of the RNA structure.
    """
    stack = []
    total_energy = 0.0

    # Traverse each nucleotide in the structure
    for i, char in enumerate(structure):
        if char == '(':  # Opening bracket, push to stack
            stack.append(i)
        elif char == ')':  # Closing bracket, pop from stack and calculate energy
            if stack:
                j = stack.pop()
                pair = sequence[j] + sequence[i]  # Form the base pair

                # Retrieve energy if pair is in dictionary, else assume zero
                pair_energy = bond_energies.get(pair, 0)
                total_energy += pair_energy

    return total_energy

# Calculate bond energies for each row in the dataset
df['Bond Energy'] = df.apply(lambda row: calculate_bond_energy(row['Structure'], row['Nucleotide Sequence']), axis=1)

# Save the updated DataFrame to a new CSV file
df.to_csv('/content/rna_sequences_with_bond_energy.csv', index=False)

"""##Visualisation"""

pip install rnaglib

import pandas as pd
import matplotlib.pyplot as plt

# Load your RNA dataset
file_path = 'rna_sequences.csv'  # Update with your actual file path
data = pd.read_csv(file_path)

# Display the first few rows of the dataset
print(data.head())

# Extract the nucleotide sequence and the dot-bracket notation
nucleotide_sequences = data['Nucleotide Sequence']
dot_bracket_structures = data['Structure']